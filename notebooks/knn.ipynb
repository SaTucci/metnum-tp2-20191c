{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/tejo240/.pyenv/versions/3.6.5/bin/python (found version \"3.6.5\") \n",
      "-- Found PythonLibs: /home/tejo240/.pyenv/versions/3.6.5/lib/libpython3.6m.a\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/knn.cpp:\u001b[m\u001b[K In member function â€˜\u001b[01m\u001b[Kdouble KNNClassifier::_predict_row(Vector)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/knn.cpp:44:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      "     for(int i = 0; \u001b[01;35m\u001b[Ki < n_neighbors\u001b[m\u001b[K; i++){\n",
      "                    \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/eigen.cpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kstd::pair<double, Eigen::Matrix<double, -1, 1> > power_iteration(const Matrix&, unsigned int, double)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/eigen.cpp:13:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      "     for(int i = 0; \u001b[01;35m\u001b[Ki < num_iter\u001b[m\u001b[K; i++){\n",
      "                    \u001b[01;35m\u001b[K~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/eigen.cpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kstd::pair<Eigen::Matrix<double, -1, 1>, Eigen::Matrix<double, -1, -1, 1> > get_first_eigenvalues(const Matrix&, unsigned int, unsigned int, double)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/src/eigen.cpp:31:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      "     for(int i = 0; \u001b[01;35m\u001b[Ki < num\u001b[m\u001b[K; i++){\n",
      "                    \u001b[01;35m\u001b[K~~^~~~~\u001b[m\u001b[K\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/notebooks/sentiment.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tejo240/Documents/Facultad/MÃ©todos NumÃ©ricos/metnum-tp2-20191c/notebooks\n",
      "Python 3.6.5\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: *.tgz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>Walker Texas Ranger is one of the worst shows ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>938_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  Walker Texas Ranger is one of the worst shows ...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "             file  \n",
       "count       12500  \n",
       "unique      12085  \n",
       "top     938_1.txt  \n",
       "freq            2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 6225\n",
      "Cantidad de instancias de test = 6275\n"
     ]
    }
   ],
   "source": [
    "text_train = df[df.type == 'train'][\"review\"]\n",
    "label_train = df[df.type == 'train'][\"label\"]\n",
    "\n",
    "text_test = df[df.type == 'test'][\"review\"]\n",
    "label_test = df[df.type == 'test'][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.49493975903614457 pos 0.5050602409638554 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "\n",
    "clf = sentiment.KNNClassifier(100)\n",
    "#esta linea y el siguiente bloque son para correr KNN sin PCA\n",
    "#esta comentado para poder ejecutar todos los bloques sin ejecutar este\n",
    "#por equivocacion\n",
    "#clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#y_pred = clf.predict(X_test)\n",
    "\n",
    "#acc = accuracy_score(y_test, y_pred)\n",
    "#print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sentiment.PCA(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train,10000, 0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train = pca.transform(X_train, 5)\n",
    "pca_X_test = pca.transform(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[ -6.90497268  -2.81010477  -0.93969949  -2.6381538   -2.85025472]\n",
      " [ -7.81907144   1.4215357   -1.45152066   2.06105015   0.62981852]\n",
      " [ -3.26337631  -1.48763321  -0.44734354  -0.95986524   1.96630703]\n",
      " ...\n",
      " [-18.35496461  -0.47617457  -2.7777734    4.01547945   3.0803519 ]\n",
      " [ -6.3272365   -0.23604173   1.11981217   2.20128377  -0.3660268 ]\n",
      " [-18.26258536   0.67115043  -1.17023443  -2.0891063    5.85577905]]\n"
     ]
    }
   ],
   "source": [
    "print(pca_X_test.shape[1])\n",
    "print(pca_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5655776892430279\n",
      "CPU times: user 2.15 s, sys: 7.71 ms, total: 2.16 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(pca_X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_pred = clf.predict(pca_X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All in one. Thuis cell defines the tester functions.\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def test(pca, max_df_=0.90, min_df_=0.01, max_features_=5000, knn_neighbours_=100, alpha_=30, log=False):\n",
    "\n",
    "    vectorizer = CountVectorizer(max_df=max_df_, min_df=min_df_, max_features=max_features_)\n",
    "    vectorizer.fit(text_train)\n",
    "\n",
    "    X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "    X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "    import sentiment\n",
    "\n",
    "    clf = sentiment.KNNClassifier(knn_neighbours_)\n",
    "    #esta linea y el siguiente bloque son para correr KNN sin PCA\n",
    "    #esta comentado para poder ejecutar todos los bloques sin ejecutar este\n",
    "    #por equivocacion\n",
    "    #clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    pca_X_train = pca.transform(X_train, alpha_)\n",
    "    pca_X_test = pca.transform(X_test,alpha_)\n",
    "\n",
    "    #Timing starts, same as previous cell:\n",
    "    start = time.time()\n",
    "\n",
    "    clf.fit(pca_X_train, y_train)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    y_pred = clf.predict(pca_X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "\n",
    "    #Timing ends, again, like in previous cell.\n",
    "    end = time.time()\n",
    "    delta_time = end - start\n",
    "    delta_time_str = str(round(delta_time, 2))\n",
    "    if log:\n",
    "        comma = \", \"\n",
    "        f = open(\"../data/test_results/out.csv\",\"a+\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(str(round(acc,2)) + comma)\n",
    "        f.write(str(round(pre,2)) + comma)\n",
    "        f.write(str(round(rec,2)) + comma)\n",
    "        f.write(delta_time_str + comma)\n",
    "        f.write(str(round(max_df_,2)) + comma)\n",
    "        f.write(str(round(min_df_,2)) + comma)\n",
    "        f.write(str(round(max_features_,2)) + comma)\n",
    "        f.write(str(round(knn_neighbours_,2)) + comma)\n",
    "        f.write(str(round(alpha_,2)))\n",
    "        f.close()\n",
    "\n",
    "    else:\n",
    "        print(\"Time:\" + delta_time_str)\n",
    "        print(\"Accuracy: {}\".format(acc))\n",
    "        print(\"Precision: {}\".format(pre))\n",
    "        print(\"Recall: {}\".format(rec))\n",
    "    return pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:2.61\n",
      "Accuracy: 0.6124302788844621\n",
      "Precision: 0.6155717761557178\n",
      "Recall: 0.5718437197287698\n"
     ]
    }
   ],
   "source": [
    "#Actual testing, this cell runs the tester functions and logs or prints results.\n",
    "#It may take a long time to run.\n",
    "import numpy as np\n",
    "#OJO, puse esto en true para testear\n",
    "test_individually = True\n",
    "if test_individually:\n",
    "    max_alpha = 90\n",
    "    pca = sentiment.PCA(max_alpha)\n",
    "    pca.fit(X_train,10000, 0.0000000001)\n",
    "    test(pca, max_df_=0.90, min_df_=0.01, max_features_=5000, knn_neighbours_=100, alpha_=20, log=False)\n",
    "else:\n",
    "    max_alpha = 140\n",
    "    pca = sentiment.PCA(alpha_)\n",
    "    pca.fit(X_train,10000, 0.0000000001)\n",
    "    for max_df_ in np.arange(0.90, 0.91, 0.05):\n",
    "        for min_df_ in np.arange(0.01, 0.02, 0.01):\n",
    "            for max_features_ in range(5000, 10000, 2000):\n",
    "                for knn_neighbours_ in range(100, 900, 200):\n",
    "                    #no se si escribi bien el range, pero la idea es ir del max_alpha hacia abajo asi\n",
    "                    #te ahorras tener que hacer el fit para cada alpha\n",
    "                    #(y de hecho saque el fit de la funcion test por este motivo)\n",
    "                    for alpha_ in range(max_alpha, 30, 30):\n",
    "                        test(pca, max_df_, min_df_, max_features_, knn_neighbours_, alpha_, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(p0, start_value):\n",
    "    step0 = 0.01\n",
    "    step1 = 0.01\n",
    "    step2 = 500\n",
    "    step3 = 20\n",
    "    step4 = 100\n",
    "    \n",
    "    old_val = start_value\n",
    "    max_index = 0\n",
    "    sign = 1\n",
    "    new_max=0\n",
    "    changed = False\n",
    "\n",
    "    p1 = []        \n",
    "    \n",
    "    next_val = test(max(0,p0[0]+step0), p0[1], p0[2], p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0]+step0, p0[1], p0[2], p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "        \n",
    "    next_val = test(max(0,p0[0]-step0), p0[1], p0[2], p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0]-step0, p0[1], p0[2], p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "    \n",
    "    next_val = test(p0[0], max(0,p0[1]+step1), p0[2], p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1]+step1, p0[2], p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True    \n",
    "    next_val = test(p0[0], max(0,p0[1]-step1), p0[2], p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1]-step1, p0[2], p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "        \n",
    "    next_val = test(p0[0], p0[1], max(0,p0[2]+step2), p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2]+step2, p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "    next_val = test(p0[0], p0[1], max(0,p0[2]-step2), p0[3], p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2]-step2, p0[3], p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "    \n",
    "    next_val = test(p0[0], p0[1], p0[2], max(0,p0[3]+step3), p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2], p0[3]+step3, p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "    next_val = test(p0[0], p0[1], p0[2], max(0,p0[3]-step3), p0[4], log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2], p0[3]-step3, p0[4]]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "        \n",
    "    next_val = test(p0[0], p0[1], p0[2], p0[3], max(0,p0[4]+step4), log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2], p0[3], p0[4]+step4]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "    \n",
    "    next_val = test(p0[0], p0[1], p0[2], p0[3], max(0,p0[4]-step4), log=True)\n",
    "    p1 = [p0[0], p0[1], p0[2], p0[3], p0[4]-step4]\n",
    "    if new_max > old_val:\n",
    "        old_val = new_max\n",
    "        changed = True\n",
    "        \n",
    "\n",
    "    \n",
    "    if not changed:\n",
    "        f = open(\"../data/test_results/out.csv\",\"a+\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"Local maximum found, ending gradient descent\")\n",
    "        f.close()\n",
    "        exit()\n",
    "    \n",
    "    f = open(\"../data/test_results/out.csv\",\"a+\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Exploration finished, starting new one with accuracy:\" + str(old_val))\n",
    "    f.close()\n",
    "    \n",
    "    gradient_descent(p1, old_val)\n",
    "        \n",
    "p0 = [0.90, 0.01,5000, 100, 30]\n",
    "gradient_descent(p0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
